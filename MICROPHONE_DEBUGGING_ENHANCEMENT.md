# Microphone Debugging Enhancement

## Problem
Microphone not starting when accepting call from foreground notification. WebRTC diagnostic logs showed:
```
ğŸŒ [WebRTC-JS] âŒâŒâŒ [WebRTC] NO LOCAL STREAM - getUserMedia() not called or failed!
ğŸŒ [WebRTC-JS] ğŸ¤ [WebRTC] Sender 0: kind=audio, enabled=true, state=ended
```

**Root Cause**: `localStream` was **null** at connection time, meaning `getUserMedia()` was either:
1. Not called yet
2. Failed silently
3. Returned an invalid stream

## Solution
Added comprehensive logging throughout the WebRTC initialization flow to track exactly when and why `getUserMedia()` fails or doesn't get called.

### Changes Made

#### 1. Enhanced `initializeLocalStream()` Function
**File**: `/Enclosure/VoiceCallAssets/scriptVoice.js`

Added logging at every step:
- When function is called
- When calling `getUserMedia()`
- When stream is returned
- Track details (count, state, enabled)
- Error details (name, message)
- Fallback constraint attempts

```javascript
const initializeLocalStream = async () => {
    console.log('ğŸ¤ [initializeLocalStream] Called - starting getUserMedia()');
    if (typeof Android !== 'undefined' && Android.logToNative) {
        Android.logToNative('ğŸ¤ [WebRTC] initializeLocalStream() called');
    }
    
    try {
        // ... getUserMedia() call ...
        
        console.log('âœ… [initializeLocalStream] getUserMedia() returned stream');
        if (typeof Android !== 'undefined' && Android.logToNative) {
            Android.logToNative('âœ… [WebRTC] getUserMedia() returned stream successfully');
        }
        
        // Log each audio track
        audioTracks.forEach((track, index) => {
            console.log(`âœ… [initializeLocalStream] Track ${index}: id=${track.id}, enabled=${track.enabled}, state=${track.readyState}`);
            if (typeof Android !== 'undefined' && Android.logToNative) {
                Android.logToNative(`âœ… [WebRTC] Track ${index}: id=${track.id}, enabled=${track.enabled}, state=${track.readyState}`);
            }
        });
    } catch (err) {
        console.error('âŒ [initializeLocalStream] getUserMedia() failed:', err);
        if (typeof Android !== 'undefined' && Android.logToNative) {
            Android.logToNative('âŒâŒâŒ [WebRTC] getUserMedia() FAILED: ' + err.name + ' - ' + err.message);
        }
    }
}
```

#### 2. Enhanced `peer.on('open')` Handler
Added logging when PeerJS connects and triggers `getUserMedia()`:

```javascript
peer.on('open', id => {
    // ... connection setup ...
    
    if (typeof Android !== 'undefined' && Android.logToNative) {
        Android.logToNative('ğŸ“ [WebRTC] PeerJS connected - initializing microphone');
        Android.logToNative('ğŸ“ [WebRTC] Calling getUserMedia() to get local stream...');
    }
    
    initializeLocalStream()
        .then(stream => {
            if (typeof Android !== 'undefined' && Android.logToNative) {
                Android.logToNative('âœ…âœ…âœ… [WebRTC] getUserMedia() SUCCESS in peer.on(open)');
                Android.logToNative('âœ… [WebRTC] Local stream created with ' + stream.getAudioTracks().length + ' audio tracks');
            }
        })
        .catch(err => {
            if (typeof Android !== 'undefined' && Android.logToNative) {
                Android.logToNative('âŒâŒâŒ [WebRTC] getUserMedia() FAILED in peer.on(open): ' + err.message);
            }
        });
});
```

#### 3. Enhanced `peer.on('call')` Handler
Added logging when receiving incoming call to track stream status:

```javascript
peer.on('call', incomingCall => {
    if (typeof Android !== 'undefined' && Android.logToNative) {
        Android.logToNative('ğŸ“ [WebRTC] Incoming call from peer: ' + incomingCall.peer);
        Android.logToNative('ğŸ“ [WebRTC] Local stream status: ' + (localStream ? 'EXISTS' : 'NULL'));
    }

    if (!localStream) {
        if (typeof Android !== 'undefined' && Android.logToNative) {
            Android.logToNative('âŒ [WebRTC] NO local stream - calling getUserMedia() now');
        }
        
        initializeLocalStream()
            .then(stream => {
                if (typeof Android !== 'undefined' && Android.logToNative) {
                    Android.logToNative('âœ… [WebRTC] getUserMedia() SUCCESS - got local stream');
                    Android.logToNative('âœ… [WebRTC] Audio tracks: ' + stream.getAudioTracks().length);
                    stream.getAudioTracks().forEach((track, i) => {
                        Android.logToNative(`âœ… [WebRTC] Track ${i}: enabled=${track.enabled}, state=${track.readyState}`);
                    });
                }
                // Answer call...
            });
    } else {
        if (typeof Android !== 'undefined' && Android.logToNative) {
            Android.logToNative('âœ… [WebRTC] Local stream already exists');
            localStream.getAudioTracks().forEach((track, i) => {
                Android.logToNative(`âœ… [WebRTC] Track ${i}: enabled=${track.enabled}, state=${track.readyState}`);
            });
        }
    }
});
```

## Expected Diagnostic Output

### Success Case (Microphone Working)
```
ğŸ¤ [WebRTC] initializeLocalStream() called
ğŸ¤ [WebRTC] Calling navigator.mediaDevices.getUserMedia()...
âœ… [WebRTC] getUserMedia() returned stream successfully
âœ… [WebRTC] Got 1 audio tracks from getUserMedia()
âœ… [WebRTC] Track 0: id=xxx, enabled=true, state=live
ğŸ“ [WebRTC] Incoming call from peer: xxx
ğŸ“ [WebRTC] Local stream status: EXISTS
âœ… [WebRTC] Local stream already exists
âœ… [WebRTC] Track 0: enabled=true, state=live
```

### Failure Case (Need to Fix)
```
ğŸ¤ [WebRTC] initializeLocalStream() called
ğŸ¤ [WebRTC] Calling navigator.mediaDevices.getUserMedia()...
âŒâŒâŒ [WebRTC] getUserMedia() FAILED: [Error details]
```

OR

```
ğŸ“ [WebRTC] Incoming call from peer: xxx
ğŸ“ [WebRTC] Local stream status: NULL
âŒ [WebRTC] NO local stream - calling getUserMedia() now
```

## Next Steps

1. **Test Call from Foreground**: Accept call when app is in foreground
2. **Check Xcode Console**: Look for `ğŸŒ [WebRTC-JS]` logs
3. **Analyze Results**:
   - If `getUserMedia()` is called but fails â†’ Check error message
   - If `getUserMedia()` succeeds but tracks are "ended" â†’ Stream lifecycle issue
   - If `getUserMedia()` is not called at all â†’ PeerJS event timing issue

## Files Modified
- `/Enclosure/VoiceCallAssets/scriptVoice.js` - Added comprehensive getUserMedia() logging

## Testing Instructions

1. **Clean build and run** on device
2. **Make call from Android**
3. **Accept from iOS foreground notification**
4. **Check Xcode console** for:
   - `ğŸ¤ [WebRTC] initializeLocalStream() called`
   - `âœ… [WebRTC] getUserMedia() SUCCESS` or `âŒ [WebRTC] getUserMedia() FAILED`
   - `ğŸ“ [WebRTC] Local stream status: EXISTS` or `NULL`
   - Track state: `state=live` or `state=ended`

## Expected Outcome
This enhanced logging will reveal:
1. When `getUserMedia()` is called
2. If it succeeds or fails
3. The state of audio tracks when call connects
4. Whether the stream exists when answering the call

This will allow us to pinpoint the exact root cause and implement the correct fix.
