import Foundation
import FirebaseDatabase
import AVFoundation
import AudioToolbox
import WebKit
import UIKit

final class VideoCallSession: ObservableObject {
    @Published var shouldDismiss = false

    private let payload: VideoCallPayload
    private let roomId: String
    private let myUid: String
    private let myName: String
    private let myPhoto: String

    private var myPeerId: String?
    private var peersHandle: DatabaseHandle?
    private var signalingHandle: DatabaseHandle?
    private var databaseRef: DatabaseReference?
    private weak var webView: WKWebView?

    private let audioSession = AVAudioSession.sharedInstance()
    private var interruptionObserver: NSObjectProtocol?
    private var routeChangeObserver: NSObjectProtocol?
    private var isAudioInterrupted = false
    private var isReconfiguringAudioForCall = false
    private var ringtonePlayer: AVAudioPlayer?
    private var ringtoneKeepAliveTimer: Timer?
    private var isCallConnected = false
    private var ringtoneSystemSoundId: SystemSoundID = 0
    private var ringtoneSystemSoundTimer: Timer?
    private var proximityObserver: NSObjectProtocol?

    private var callKitAudioReadyObserver: NSObjectProtocol?
    private var isWaitingForCallKitAudio = false

    private var mediaStartRetryWorkItem: DispatchWorkItem?
    private var mediaStartRetryAttempts = 0
    private let maxMediaStartRetryAttempts = 5

    private var isPageReady = false

    private var removeCallNotificationSent = false
    private var isCallEnded = false

    init(payload: VideoCallPayload) {
        self.payload = payload
        self.roomId = payload.roomId ?? Self.generateRoomId()
        self.myUid = UserDefaults.standard.string(forKey: Constant.UID_KEY) ?? ""
        self.myName = UserDefaults.standard.string(forKey: Constant.full_name) ?? "Name"
        self.myPhoto = UserDefaults.standard.string(forKey: Constant.profilePic) ?? ""
    }

    func attach(webView: WKWebView) {
        self.webView = webView
    }

    /// Call from WKNavigationDelegate didFinish so caller name/photo show as soon as page loads (before onPageReady from script).
    func sendCallerInfoToWebViewIfNeeded() {
        let safePhoto = payload.receiverPhoto.isEmpty ? "user.png" : payload.receiverPhoto
        let safeName = payload.receiverName.isEmpty ? "Name" : payload.receiverName
        sendToWebView("if (typeof setRemoteCallerInfo === 'function') { setRemoteCallerInfo('\(jsEscaped(safePhoto))', '\(jsEscaped(safeName))'); }")
        sendToWebView("if (typeof setThemeColor === 'function') { setThemeColor('\(jsEscaped(Constant.themeColor))'); }")
    }

    /// Call before loading the WebView URL so camera/mic are requested and WKWebView getUserMedia sees granted state.
    func requestCameraAndMicrophoneAccessIfNeeded() {
        requestCameraAndMicrophoneAccess()
    }

    func start() {
        isCallConnected = false
        isPageReady = false
        requestCameraAndMicrophoneAccess()
        databaseRef = Database.database().reference()
        setupFirebaseListeners()
        startObservingAudioInterruptions()
        if payload.isSender {
            startRingtone()
        } else {
            // Incoming CallKit call: wait for CallKit to finish activating audio session before starting getUserMedia.
            if CallKitManager.shared.isAudioSessionReady {
                attemptStartLocalMedia(reason: "callkit_audio_already_ready")
            } else {
                isWaitingForCallKitAudio = true
                callKitAudioReadyObserver = NotificationCenter.default.addObserver(
                    forName: NSNotification.Name("CallKitAudioSessionReady"),
                    object: nil,
                    queue: .main
                ) { [weak self] _ in
                    guard let self, self.isWaitingForCallKitAudio else { return }
                    self.isWaitingForCallKitAudio = false
                    self.attemptStartLocalMedia(reason: "callkit_audio_ready")
                }

                DispatchQueue.main.asyncAfter(deadline: .now() + 2.0) { [weak self] in
                    guard let self, self.isWaitingForCallKitAudio else { return }
                    self.isWaitingForCallKitAudio = false
                    self.attemptStartLocalMedia(reason: "callkit_audio_timeout")
                }
            }
        }
    }

    func stop() {
        print("ðŸ“žðŸ“žðŸ“ž [VideoCallSession] stop() called - shouldDismiss=\(shouldDismiss), isCallEnded=\(isCallEnded)")
        // Safety net: only sender sends removeVideoCallNotification, and only if call actually ended
        if isCallEnded && payload.isSender {
            sendRemoveCallNotificationIfNeeded()
        }
        // Always clean up any entries addressed to us
        if isCallEnded {
            cleanupRemoveCallNotificationForSelf()
        }
        cleanupFirebaseListeners()
        stopObservingAudioInterruptions()
        stopRingtone(reason: "session_stop")
        disableProximitySensor()

        mediaStartRetryWorkItem?.cancel()
        mediaStartRetryWorkItem = nil

        if let observer = callKitAudioReadyObserver {
            NotificationCenter.default.removeObserver(observer)
            callKitAudioReadyObserver = nil
        }
        isWaitingForCallKitAudio = false

        // End CallKit call if still active
        if !payload.isSender {
            if let callKitUUID = CallKitManager.shared.getCallUUID(for: roomId) {
                print("ðŸ“ž [VideoCallSession] stop() - Ending CallKit call: \(callKitUUID)")
                CallKitManager.shared.endCall(uuid: callKitUUID, reason: .remoteEnded)
            }
        }
    }

    func handleMessage(_ message: [String: Any]) {
        guard let type = message["type"] as? String else { return }
        print("ðŸ“¹ [VideoCallSession] JS message: \(type)")
        switch type {
        case "sendPeerId":
            if let peerId = message["peerId"] as? String {
                print("ðŸ“¹ [VideoCallSession] Peer ID received from JS: \(peerId)")
                handleSendPeerId(peerId)
            }
        case "toggleMicrophone":
            if let mute = message["mute"] as? Bool {
                setMicrophoneMuted(mute)
            }
        case "saveMuteState":
            if let mute = message["mute"] as? Bool {
                UserDefaults.standard.set(mute, forKey: "video_call_muted")
            }
        case "onPeerConnected":
            // Do NOT re-request permissions or re-trigger getUserMedia here.
            // The local stream is already live and connected to the peer.
            print("ðŸ“¹ [VideoCallSession] Peer connected")
        case "onCallConnected":
            // Guard: only process the first onCallConnected. JS fires this multiple times
            // (once per stream event). Repeated calls to updateVideoLayout() reset the layout
            // and can put local video back on primary if remoteStream is momentarily null.
            guard !isCallConnected else {
                print("ðŸ“¹ [VideoCallSession] onCallConnected IGNORED (already connected)")
                return
            }
            isCallConnected = true
            print("ðŸ“¹ [VideoCallSession] onCallConnected - FIRST TIME, applying layout")
            stopRingtone(reason: "call_connected")
            enableProximitySensor()
            // CRITICAL: Do NOT call reconfigureAudioSessionForCall() here.
            // CRITICAL: Do NOT call requestCameraAndMicrophonePermissionIfNeeded() here.
            //
            // Use applyConnectedLayoutFromPeers only (not updateVideoLayout which clears everything first).
            // applyConnectedLayoutFromPeers directly sets remoteâ†’primary, localâ†’secondary without clearing.
            let layoutJS = "if (typeof applyConnectedLayoutFromPeers === 'function') applyConnectedLayoutFromPeers();"
            DispatchQueue.main.async { [weak self] in
                self?.sendToWebView(layoutJS)
            }
            // Single delayed retry to ensure stream is attached
            DispatchQueue.main.asyncAfter(deadline: .now() + 1.0) { [weak self] in
                self?.sendToWebView(layoutJS)
            }
        case "endCall":
            print("ðŸ“žðŸ“žðŸ“ž [VideoCallSession] JS triggered endCall")
            endCall()
        case "callOnBackPressed":
            print("ðŸ“žðŸ“žðŸ“ž [VideoCallSession] JS triggered callOnBackPressed")
            if payload.isSender {
                sendRemoveCallNotificationIfNeeded()
            }
            stopRingtone(reason: "back_pressed")
            disableProximitySensor()
            shouldDismiss = true
        case "addMemberBtn":
            // TODO: Implement add member functionality
            break
        case "onPageReady":
            handlePageReady()
        case "toggleFullScreen":
            // Video calls handle fullscreen in WebView
            break
        case "enterPiPMode":
            // Picture-in-picture mode handled in WebView
            break
        case "sendSignalingData":
            if let data = message["data"] as? String {
                sendSignalingData(data)
            }
        default:
            break
        }
    }

    private func handlePageReady() {
        sendToWebView("setRoomId('\(jsEscaped(roomId))')")
        let safePhoto = payload.receiverPhoto.isEmpty ? "user.png" : payload.receiverPhoto
        let safeName = payload.receiverName.isEmpty ? "Name" : payload.receiverName
        sendToWebView("setRemoteCallerInfo('\(jsEscaped(safePhoto))', '\(jsEscaped(safeName))')")
        sendToWebView("setThemeColor('\(jsEscaped(Constant.themeColor))')")
        isPageReady = true
        // Default: start unmuted (do not restore saved mute state so mic is unmuted by default)
        // Start local media after page is ready (guard in JS prevents double init)
        DispatchQueue.main.asyncAfter(deadline: .now() + 0.5) { [weak self] in
            self?.attemptStartLocalMedia(reason: "page_ready")
        }
    }

    private func handleSendPeerId(_ peerId: String) {
        myPeerId = peerId

        guard let databaseRef else { return }
        let peerPayload: [String: Any] = [
            "peerId": peerId,
            "name": myName,
            "photo": myPhoto.isEmpty ? "user.png" : myPhoto
        ]

        if let data = try? JSONSerialization.data(withJSONObject: peerPayload, options: []),
           let jsonString = String(data: data, encoding: .utf8) {
            databaseRef.child("rooms").child(roomId).child("peers").child(peerId).setValue(jsonString)
        }
    }

    private func setupFirebaseListeners() {
        guard let databaseRef else { return }

        peersHandle = databaseRef.child("rooms").child(roomId).child("peers")
            .observe(.value) { [weak self] snapshot in
                guard let self else { return }
                var peerIds: [String] = []
                var seen = Set<String>()

                for child in snapshot.children {
                    guard
                        let childSnapshot = child as? DataSnapshot,
                        let value = childSnapshot.value as? String,
                        let data = value.data(using: .utf8),
                        let json = try? JSONSerialization.jsonObject(with: data) as? [String: Any]
                    else { continue }

                    let peerId = json["peerId"] as? String ?? ""
                    if peerId.isEmpty || seen.contains(peerId) { continue }
                    seen.insert(peerId)
                    peerIds.append(peerId)

                    // Note: Video call script.js uses updatePeers and setRemoteCallerInfo, not setCallerInfo
                }

                // Android parity: when peer count drops to 0 (room deleted by other side),
                // auto-end the call on this side too (setupDeleteListers behavior).
                // IMPORTANT: Only trigger after our own peer has been written (myPeerId != nil).
                // Before that, peerCount=0 is expected (empty room at call start).
                let peerCount = snapshot.childrenCount
                NSLog("ðŸ“¹ [VideoCallSession] Peers listener: peerCount=\(peerCount), myPeerId=\(self.myPeerId ?? "nil")")
                if peerCount == 0 && !self.isCallEnded && self.myPeerId != nil {
                    NSLog("ðŸ“¹ [VideoCallSession] Peers dropped to 0 - other side ended call, auto-ending")
                    DispatchQueue.main.async {
                        self.endCall()
                    }
                    return
                }

                if let peersJsonData = try? JSONSerialization.data(withJSONObject: ["peers": peerIds], options: []),
                   let peersJson = String(data: peersJsonData, encoding: .utf8) {
                    sendToWebView("updatePeers(\(peersJson))")
                }
            }

        signalingHandle = databaseRef.child("rooms").child(roomId).child("signaling")
            .observe(.value) { [weak self] snapshot in
                guard let self else { return }
                for child in snapshot.children {
                    guard let childSnapshot = child as? DataSnapshot,
                          let value = childSnapshot.value as? String,
                          let data = value.data(using: .utf8),
                          let jsonObject = try? JSONSerialization.jsonObject(with: data) as? [String: Any]
                    else { continue }

                    let receiver = jsonObject["receiver"] as? String ?? ""
                    if receiver == myPeerId || receiver == "all" {
                        if let jsonString = String(data: data, encoding: .utf8) {
                            sendToWebView("handleSignalingData(\(jsonString))")
                            childSnapshot.ref.removeValue()
                        }
                    }
                }
            }
    }

    private func cleanupFirebaseListeners() {
        guard let databaseRef else { return }
        if let peersHandle {
            databaseRef.child("rooms").child(roomId).child("peers").removeObserver(withHandle: peersHandle)
            self.peersHandle = nil
        }
        if let signalingHandle {
            databaseRef.child("rooms").child(roomId).child("signaling").removeObserver(withHandle: signalingHandle)
            self.signalingHandle = nil
        }
        // Android parity: remove entire room when call ended so the other side
        // sees peerCount=0 and auto-ends. Only remove entire room if endCall() was triggered.
        // Otherwise just remove own peer (e.g. stop() called during view lifecycle).
        if isCallEnded {
            databaseRef.child("rooms").child(roomId).removeValue { error, _ in
                if let error = error {
                    NSLog("âš ï¸ [VideoCallSession] Failed to remove room: \(error.localizedDescription)")
                } else {
                    NSLog("âœ… [VideoCallSession] Room removed: \(self.roomId)")
                }
            }
        } else if let peerId = myPeerId {
            databaseRef.child("rooms").child(roomId).child("peers").child(peerId).removeValue()
        }
    }

    func requestCameraAndMicrophonePermissionIfNeeded() {
        let cameraStatus = AVCaptureDevice.authorizationStatus(for: .video)
        let micStatus = audioSession.recordPermission

        print("ðŸ“¹ [VideoCallSession] Checking permissions - Camera: \(cameraStatus.rawValue), Mic: \(micStatus.rawValue)")

        if cameraStatus == .notDetermined {
            print("ðŸ“¹ [VideoCallSession] Requesting camera permission...")
            AVCaptureDevice.requestAccess(for: .video) { [weak self] granted in
                print("ðŸ“¹ [VideoCallSession] Camera permission result: \(granted)")
                DispatchQueue.main.async {
                    self?.attemptStartLocalMedia(reason: "camera_permission_result")
                }
            }
        }

        if micStatus == .undetermined {
            print("ðŸŽ¤ [VideoCallSession] Requesting microphone permission...")
            audioSession.requestRecordPermission { [weak self] granted in
                print("ðŸŽ¤ [VideoCallSession] Microphone permission result: \(granted)")
                DispatchQueue.main.async {
                    self?.attemptStartLocalMedia(reason: "mic_permission_result")
                }
            }
        }

        attemptStartLocalMedia(reason: "permission_check")
    }

    private func attemptStartLocalMedia(reason: String) {
        guard let webView else { return }

        // Don't start getUserMedia until the page JS is ready.
        guard isPageReady else { return }

        // Reset retry attempts on each fresh start attempt.
        mediaStartRetryAttempts = 0

        // For incoming CallKit calls, don't start getUserMedia until CallKit has activated audio.
        if !payload.isSender, !CallKitManager.shared.isAudioSessionReady {
            return
        }

        let cameraStatus = AVCaptureDevice.authorizationStatus(for: .video)
        let micStatus = audioSession.recordPermission
        guard cameraStatus == .authorized, micStatus == .granted else {
            return
        }

        let js = "if (typeof startLocalStreamWithRetry === 'function') { startLocalStreamWithRetry(0); } else if (typeof initializeLocalStream === 'function') { initializeLocalStream().catch(function(){}); }"
        webView.evaluateJavaScript(js) { _, error in
            if let error = error {
                print("âš ï¸ [VideoCallSession] Failed to start local media (\(reason)): \(error.localizedDescription)")
            } else {
                print("ðŸ“¹ [VideoCallSession] Triggered local media start (\(reason))")
            }
        }

        scheduleMediaStartVerificationAndRetry(webView: webView)
    }

    private func scheduleMediaStartVerificationAndRetry(webView: WKWebView) {
        guard !payload.isSender else { return }

        if mediaStartRetryAttempts >= maxMediaStartRetryAttempts {
            return
        }

        mediaStartRetryAttempts += 1

        mediaStartRetryWorkItem?.cancel()

        let work = DispatchWorkItem { [weak self, weak webView] in
            guard let self, let webView else { return }

            if UIApplication.shared.applicationState != .active {
                return
            }

            let checkJS = "(function(){try{var s=window.localStream; if(!s) return false; var ts=s.getTracks? s.getTracks(): []; if(!ts||!ts.length) return false; for(var i=0;i<ts.length;i++){var t=ts[i]; if(t && t.readyState==='live') return true;} return false;}catch(e){return false;}})();"
            webView.evaluateJavaScript(checkJS) { [weak self] result, _ in
                guard let self else { return }
                let started = (result as? Bool) ?? false
                if started {
                    self.mediaStartRetryAttempts = 0
                    return
                }

                let retryJS = "if (typeof startLocalStreamWithRetry === 'function') { startLocalStreamWithRetry(0); } else if (typeof initializeLocalStream === 'function') { initializeLocalStream().catch(function(){}); }"
                webView.evaluateJavaScript(retryJS, completionHandler: nil)

                DispatchQueue.main.asyncAfter(deadline: .now() + 1.0) {
                    self.scheduleMediaStartVerificationAndRetry(webView: webView)
                }
            }
        }

        mediaStartRetryWorkItem = work
        DispatchQueue.main.asyncAfter(deadline: .now() + 1.0, execute: work)
    }

    private func requestCameraAndMicrophoneAccess() {
        let cameraStatus = AVCaptureDevice.authorizationStatus(for: .video)
        let micStatus = audioSession.recordPermission
        
        if cameraStatus == .denied || micStatus == .denied {
            DispatchQueue.main.async {
                Constant.showToast(message: "Camera and microphone permissions are required for video calls.")
            }
            return
        }
        
        if cameraStatus == .notDetermined {
            AVCaptureDevice.requestAccess(for: .video) { [weak self] granted in
                if granted {
                    self?.requestMicrophoneAccess()
                } else {
                    DispatchQueue.main.async {
                        Constant.showToast(message: "Camera permission is required for video calls.")
                    }
                }
            }
        } else {
            requestMicrophoneAccess()
        }
    }

    private func requestMicrophoneAccess() {
        switch audioSession.recordPermission {
        case .granted:
            ensureAudioSessionActive()
            attemptStartLocalMedia(reason: "mic_already_granted")
        case .denied:
            DispatchQueue.main.async {
                Constant.showToast(message: "Microphone permission is required for video calls.")
            }
        case .undetermined:
            audioSession.requestRecordPermission { [weak self] granted in
                DispatchQueue.main.async {
                    if granted {
                        self?.ensureAudioSessionActive()
                        self?.attemptStartLocalMedia(reason: "mic_granted_request")
                    } else {
                        Constant.showToast(message: "Microphone permission is required for video calls.")
                    }
                }
            }
        @unknown default:
            break
        }
    }

    private func startObservingAudioInterruptions() {
        guard interruptionObserver == nil else { return }
        interruptionObserver = NotificationCenter.default.addObserver(
            forName: AVAudioSession.interruptionNotification,
            object: nil,
            queue: .main
        ) { [weak self] notification in
            guard let self else { return }
            guard let info = notification.userInfo,
                  let typeValue = info[AVAudioSessionInterruptionTypeKey] as? UInt,
                  let type = AVAudioSession.InterruptionType(rawValue: typeValue) else { return }
            
            switch type {
            case .began:
                if self.isReconfiguringAudioForCall { return }
                if !self.isAudioInterrupted {
                    self.isAudioInterrupted = true
                    print("ðŸ”‡ [VideoCallSession] Audio interruption began")
                }
            case .ended:
                if self.isAudioInterrupted {
                    self.isAudioInterrupted = false
                    print("ðŸ”Š [VideoCallSession] Audio interruption ended")
                    if let optionsValue = info[AVAudioSessionInterruptionOptionKey] as? UInt {
                        let options = AVAudioSession.InterruptionOptions(rawValue: optionsValue)
                        if options.contains(.shouldResume) {
                            // Small delay to avoid "already interrupted" errors
                            DispatchQueue.main.asyncAfter(deadline: .now() + 0.1) {
                                self.ensureAudioSessionActive()
                            }
                        }
                    } else {
                        DispatchQueue.main.asyncAfter(deadline: .now() + 0.1) {
                            self.ensureAudioSessionActive()
                        }
                    }
                }
            @unknown default:
                break
            }
        }
    }

    private func stopObservingAudioInterruptions() {
        if let observer = interruptionObserver {
            NotificationCenter.default.removeObserver(observer)
            interruptionObserver = nil
        }
        if let observer = routeChangeObserver {
            NotificationCenter.default.removeObserver(observer)
            routeChangeObserver = nil
        }
    }

    /// Call when the call connects: deactivate session to clear "already interrupted" state, then reconfigure for video chat.
    private func reconfigureAudioSessionForCall() {
        guard audioSession.recordPermission == .granted else { return }
        isReconfiguringAudioForCall = true
        do {
            try audioSession.setActive(false, options: [.notifyOthersOnDeactivation])
        } catch {
            // Ignore
        }
        isAudioInterrupted = false
        DispatchQueue.main.asyncAfter(deadline: .now() + 0.4) { [weak self] in
            guard let self else { return }
            self.ensureAudioSessionActive()
            self.isReconfiguringAudioForCall = false
        }
    }

    private func ensureAudioSessionActive() {
        guard audioSession.recordPermission == .granted else { return }
        
        // Don't try to activate if already interrupted - wait for interruption to end
        if isAudioInterrupted {
            return
        }
        
        do {
            // CRITICAL: Use .default mode (NOT .videoChat)
            // .videoChat conflicts with WKWebView's own WebRTC audio processing,
            // causing getUserMedia tracks to stay permanently muted=true.
            // .mixWithOthers is REQUIRED for WKWebView to access the microphone.
            try audioSession.setCategory(.playAndRecord, mode: .default, options: [.allowBluetooth, .defaultToSpeaker, .mixWithOthers])
            try audioSession.setActive(true, options: [.notifyOthersOnDeactivation])
        } catch {
            // Ignore "already active" or "already interrupted" errors as they're harmless
            let errorDescription = error.localizedDescription
            if !errorDescription.contains("already") && !errorDescription.contains("interrupted") {
                print("âš ï¸ [VideoCallSession] Audio session error: \(errorDescription)")
            }
        }
    }

    private func setMicrophoneMuted(_ muted: Bool) {
        if audioSession.isInputGainSettable {
            do {
                try audioSession.setInputGain(muted ? 0.0 : 1.0)
            } catch {
                print("âš ï¸ [VideoCallSession] Failed to set input gain: \(error.localizedDescription)")
            }
        }
        UserDefaults.standard.set(muted, forKey: "video_call_muted")
    }

    private func endCall() {
        guard !isCallEnded else {
            NSLog("ðŸ“¹ [VideoCallSession] endCall() IGNORED - already ended")
            return
        }
        isCallEnded = true
        // Android behavior parity: sender sends removeVideoCallNotification to dismiss
        // receiver's incoming-call/CallKit UI. Only sender sends (receiver's payload.receiverId
        // points to themselves, not the sender).
        if payload.isSender {
            sendRemoveCallNotificationIfNeeded()
        }
        // Always clean up any removeVideoCallNotification entries addressed to us
        cleanupRemoveCallNotificationForSelf()

        stopRingtone(reason: "end_call")
        cleanupFirebaseListeners()
        disableProximitySensor()

        // End CallKit call if this was an incoming CallKit call
        if !payload.isSender {
            if let callKitUUID = CallKitManager.shared.getCallUUID(for: roomId) {
                print("ðŸ“ž [VideoCallSession] Ending CallKit call: \(callKitUUID)")
                CallKitManager.shared.endCall(uuid: callKitUUID, reason: .remoteEnded)
            } else {
                print("âš ï¸ [VideoCallSession] No active CallKit call found for room: \(roomId)")
            }
        }

        shouldDismiss = true
    }

    private func sendRemoveCallNotificationIfNeeded() {
        guard !removeCallNotificationSent else { return }
        let receiverId = payload.receiverId.trimmingCharacters(in: .whitespacesAndNewlines)
        guard !receiverId.isEmpty else {
            NSLog("âš ï¸ [VideoCallSession] sendRemoveCallNotification: receiverId missing")
            return
        }
        removeCallNotificationSent = true

        let ref = Database.database().reference().child("removeVideoCallNotification").child(receiverId).childByAutoId()
        let key = ref.key ?? UUID().uuidString
        ref.setValue(key) { error, _ in
            if let error = error {
                NSLog("âš ï¸ [VideoCallSession] Failed to send removeVideoCallNotification: \(error.localizedDescription)")
            } else {
                NSLog("âœ… [VideoCallSession] removeVideoCallNotification sent to receiverId=\(receiverId), key=\(key)")
            }
        }
    }

    /// Clean up any removeVideoCallNotification entries addressed to our own UID
    /// so they don't pile up in Firebase.
    private func cleanupRemoveCallNotificationForSelf() {
        let myUid = self.myUid.trimmingCharacters(in: .whitespacesAndNewlines)
        guard !myUid.isEmpty else { return }
        Database.database().reference().child("removeVideoCallNotification").child(myUid).removeValue { error, _ in
            if let error = error {
                NSLog("âš ï¸ [VideoCallSession] Failed to cleanup removeVideoCallNotification for self: \(error.localizedDescription)")
            } else {
                NSLog("âœ… [VideoCallSession] Cleaned up removeVideoCallNotification for myUid=\(myUid)")
            }
        }
    }

    private func sendSignalingData(_ data: String) {
        guard let databaseRef else { return }
        databaseRef.child("rooms").child(roomId).child("signaling").childByAutoId().setValue(data)
    }

    private func sendToWebView(_ javascript: String) {
        DispatchQueue.main.async { [weak self] in
            self?.webView?.evaluateJavaScript("javascript:\(javascript)", completionHandler: nil)
        }
    }

    private func startRingtone() {
        guard ringtonePlayer == nil else { return }
        print("ðŸ”” [VideoCallRingtone] Starting ringtone for sender...")

        let mp3Url = Bundle.main.url(forResource: "ringtone", withExtension: "mp3", subdirectory: "VoiceCallAssets")
            ?? Bundle.main.url(forResource: "ringtone", withExtension: "mp3")
        let wavUrl = Bundle.main.url(forResource: "ringtone", withExtension: "wav", subdirectory: "VoiceCallAssets")
            ?? Bundle.main.url(forResource: "ringtone", withExtension: "wav")

        let candidateUrls = [mp3Url, wavUrl].compactMap { $0 }
        guard let ringtoneUrl = candidateUrls.first else {
            print("âš ï¸ [VideoCallRingtone] Ringtone asset not found in bundle.")
            return
        }

        do {
            try audioSession.setCategory(.playAndRecord, mode: .default, options: [.allowBluetooth, .mixWithOthers])
            try audioSession.setActive(true, options: [.notifyOthersOnDeactivation])
            
            var lastError: Error?
            var player: AVAudioPlayer?
            for url in candidateUrls {
                do {
                    let candidatePlayer = try AVAudioPlayer(contentsOf: url)
                    candidatePlayer.numberOfLoops = -1
                    candidatePlayer.volume = 1.0
                    candidatePlayer.prepareToPlay()
                    player = candidatePlayer
                    break
                } catch {
                    lastError = error
                }
            }

            guard let activePlayer = player else {
                if let lastError {
                    print("âš ï¸ [VideoCallRingtone] Failed to start ringtone: \(lastError.localizedDescription)")
                }
                startSystemRingtoneFallback()
                return
            }

            DispatchQueue.main.asyncAfter(deadline: .now() + 0.2) { [weak self] in
                guard let self else { return }
                if !activePlayer.isPlaying {
                    activePlayer.play()
                }
                self.ringtonePlayer = activePlayer
                self.startRingtoneKeepAlive()
            }
        } catch {
            print("âš ï¸ [VideoCallRingtone] Failed to start ringtone: \(error.localizedDescription)")
            startSystemRingtoneFallback()
        }
    }

    private func stopRingtone(reason: String) {
        if ringtonePlayer != nil {
            print("ðŸ”• [VideoCallRingtone] Stopping ringtone (reason=\(reason))")
        }
        ringtoneKeepAliveTimer?.invalidate()
        ringtoneKeepAliveTimer = nil
        ringtonePlayer?.stop()
        ringtonePlayer = nil
        stopSystemRingtoneFallback()
    }

    private func startRingtoneKeepAlive() {
        ringtoneKeepAliveTimer?.invalidate()
        ringtoneKeepAliveTimer = Timer.scheduledTimer(withTimeInterval: 1.0, repeats: true) { [weak self] _ in
            guard let self else { return }
            guard !self.isCallConnected else { return }
            guard let player = self.ringtonePlayer else { return }
            
            if !player.isPlaying {
                player.play()
            }
        }
    }

    private func startSystemRingtoneFallback() {
        if ringtoneSystemSoundId != 0 || ringtoneSystemSoundTimer != nil {
            return
        }

        let wavUrl = Bundle.main.url(forResource: "ringtone", withExtension: "wav", subdirectory: "VoiceCallAssets")
            ?? Bundle.main.url(forResource: "ringtone", withExtension: "wav")
        guard let soundUrl = wavUrl else {
            print("âš ï¸ [VideoCallRingtone] System sound fallback failed: wav not found")
            return
        }

        let status = AudioServicesCreateSystemSoundID(soundUrl as CFURL, &ringtoneSystemSoundId)
        if status != kAudioServicesNoError || ringtoneSystemSoundId == 0 {
            print("âš ï¸ [VideoCallRingtone] System sound fallback failed: status=\(status)")
            return
        }

        print("ðŸ”” [VideoCallRingtone] Using system sound fallback")
        ringtoneSystemSoundTimer = Timer.scheduledTimer(withTimeInterval: 1.2, repeats: true) { [weak self] _ in
            guard let self else { return }
            guard !self.isCallConnected else { return }
            AudioServicesPlaySystemSound(self.ringtoneSystemSoundId)
        }
    }

    private func stopSystemRingtoneFallback() {
        ringtoneSystemSoundTimer?.invalidate()
        ringtoneSystemSoundTimer = nil
        if ringtoneSystemSoundId != 0 {
            AudioServicesDisposeSystemSoundID(ringtoneSystemSoundId)
            ringtoneSystemSoundId = 0
        }
    }

    // MARK: - Proximity Sensor Management
    
    private func enableProximitySensor() {
        guard UIDevice.current.isProximityMonitoringEnabled == false else { return }
        
        UIDevice.current.isProximityMonitoringEnabled = true
        print("ðŸ“± [VideoCallSession] Proximity sensor enabled")
        
        proximityObserver = NotificationCenter.default.addObserver(
            forName: UIDevice.proximityStateDidChangeNotification,
            object: nil,
            queue: .main
        ) { [weak self] _ in
            guard let self = self else { return }
            let isNear = UIDevice.current.proximityState
            print("ðŸ“± [VideoCallSession] Proximity state changed: \(isNear ? "Near" : "Far")")
        }
    }
    
    private func disableProximitySensor() {
        guard UIDevice.current.isProximityMonitoringEnabled == true else { return }
        
        if let observer = proximityObserver {
            NotificationCenter.default.removeObserver(observer)
            proximityObserver = nil
        }
        
        UIDevice.current.isProximityMonitoringEnabled = false
        print("ðŸ“± [VideoCallSession] Proximity sensor disabled")
    }

    private func jsEscaped(_ value: String) -> String {
        value
            .replacingOccurrences(of: "\\", with: "\\\\")
            .replacingOccurrences(of: "'", with: "\\'")
            .replacingOccurrences(of: "\n", with: "\\n")
    }

    private static func generateRoomId() -> String {
        let timestamp = Int(Date().timeIntervalSince1970 * 1000)
        let random = Int.random(in: 1000...9999)
        return "\(timestamp)\(random)"
    }
}
