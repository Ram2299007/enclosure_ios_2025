# iOS Silent Audio Wake Fix: Bypass Audio Context Suspend Block

## Issue Identified

All THREE `audioContext.resume()` attempts **hung indefinitely**:

```
ğŸ”§ [WebRTC] Audio context suspended after getUserMedia, resuming...  â† Attempt #1 (hung)
ğŸ”§ [WebRTC] Attempting to resume audio context in peer.on(open)...  â† Attempt #2 (hung)
ğŸ”§ [WebRTC] Resuming audio context in muted track recovery...  â† Attempt #3 (hung)
â° [WebRTC] Audio context resume taking > 2s - may be blocked by iOS  â† Timeout!
```

**Result**: Track stayed `muted=true`, no audio sent to Android.

### Root Cause: iOS WKWebView Audio Policy

iOS **strictly controls** audio in WKWebView:
- Audio contexts created as `suspended` by default
- `audioContext.resume()` requires **user interaction** or **playing audio**
- CallKit activating audio session **doesn't count** for WebView JavaScript
- Simply calling `resume()` from JS is **blocked** by iOS security policy

## Solution: Play Silent Audio Element

iOS allows audio if an **audio element** is played. This "wakes" the audio system and allows `audioContext.resume()` to succeed.

### The Silent Audio Trick

#### 1. Created `playSilentAudioToWakeIOS()` Function
**File**: `/Enclosure/VoiceCallAssets/scriptVoice.js`

```javascript
const playSilentAudioToWakeIOS = async () => {
    if (!isIOSDevice()) return;
    
    console.log('ğŸ”Š [iOS Audio Wake] Playing silent audio to wake iOS audio system...');
    if (typeof Android !== 'undefined' && Android.logToNative) {
        Android.logToNative('ğŸ”Š [WebRTC] Playing silent audio to wake iOS audio system...');
    }
    
    try {
        // Create a silent audio element with data URI (no network request)
        const silentAudio = new Audio();
        silentAudio.src = 'data:audio/wav;base64,UklGRigAAABXQVZFZm10IBIAAAABAAEARKwAAIhYAQACABAAAABkYXRhAgAAAAEA';
        silentAudio.loop = false;
        silentAudio.volume = 0.01; // Very quiet
        
        // Play it
        await silentAudio.play();
        console.log('âœ… [iOS Audio Wake] Silent audio played successfully');
        if (typeof Android !== 'undefined' && Android.logToNative) {
            Android.logToNative('âœ… [WebRTC] Silent audio played - iOS audio system should be active');
        }
        
        // Remove after playing
        setTimeout(() => {
            silentAudio.pause();
            silentAudio.src = '';
        }, 100);
        
        // Now try to resume audio context
        if (audioContext && audioContext.state === 'suspended') {
            if (typeof Android !== 'undefined' && Android.logToNative) {
                Android.logToNative('ğŸ”§ [WebRTC] Attempting audio context resume AFTER silent audio...');
            }
            await audioContext.resume();
            if (typeof Android !== 'undefined' && Android.logToNative) {
                Android.logToNative('âœ…âœ…âœ… [WebRTC] Audio context RESUMED after silent audio trick!');
            }
        }
    } catch (err) {
        console.error('âŒ [iOS Audio Wake] Failed to play silent audio:', err);
        if (typeof Android !== 'undefined' && Android.logToNative) {
            Android.logToNative('âŒ [WebRTC] Silent audio play failed: ' + err.message);
        }
    }
};
```

**How It Works:**
1. Creates a tiny silent WAV file from base64 data URI (no network)
2. Sets volume to 0.01 (nearly silent, user won't hear)
3. Plays it with `audio.play()` - this "unlocks" iOS audio
4. Immediately tries `audioContext.resume()` after
5. Cleans up audio element

#### 2. Call Silent Audio at Multiple Points

**Point A: Right After getUserMedia() (in `initializeLocalStream()`)**
```javascript
if (isIOSDevice()) {
    Android.logToNative('ğŸ”Š [WebRTC] iOS detected - playing silent audio to wake system...');
    
    playSilentAudioToWakeIOS().then(() => {
        console.log('âœ… [initializeLocalStream] iOS audio wake complete');
    });
}
```

**Point B: In `peer.on('open')` After Stream Created**
```javascript
if (audioContext.state === 'suspended') {
    Android.logToNative('ğŸ”Š [WebRTC] Waking iOS audio with silent audio in peer.on(open)...');
    
    playSilentAudioToWakeIOS().then(() => {
        Android.logToNative('âœ… [WebRTC] iOS audio wake completed in peer.on(open)');
    });
}
```

**Point C: When Muted Track Detected**
```javascript
if (audioContext.state === 'suspended') {
    Android.logToNative('ğŸ”Š [WebRTC] Playing silent audio to wake iOS in muted track recovery...');
    
    playSilentAudioToWakeIOS().then(() => {
        Android.logToNative('âœ…âœ…âœ… [WebRTC] iOS audio wake complete in muted track recovery!');
    });
}
```

## Why This Works

### iOS Audio Context Rules:
- **Blocked**: Direct `audioContext.resume()` from JS âŒ
- **Allowed**: Playing `<audio>` element âœ…
- **Allowed**: `audioContext.resume()` **AFTER** playing audio âœ…

### The Sequence:
```
1. iOS blocks audioContext.resume() by default
2. Play silent audio element â†’ iOS allows it (CallKit session active)
3. Silent audio plays â†’ Wakes iOS audio system
4. audioContext.resume() â†’ Now allowed!
5. Audio context state: suspended â†’ running
6. Track unmutes (muted: true â†’ false)
7. Microphone works! âœ…
```

## Expected Behavior

### Success Logs (Should See):
```
ğŸ”Š [WebRTC] iOS detected - playing silent audio to wake system...
âœ… [WebRTC] Silent audio played - iOS audio system should be active
ğŸ”§ [WebRTC] Attempting audio context resume AFTER silent audio...
âœ…âœ…âœ… [WebRTC] Audio context RESUMED after silent audio trick!
âœ…âœ…âœ… [WebRTC] Track 0 UNMUTED - microphone is now producing audio!
```

### Track Status After Wake:
```
ğŸ¤ [WebRTC] Track 0: enabled=true, state=live, muted=false  â† UNMUTED!
```

### If First Attempt Fails (Try 2nd/3rd):
```
ğŸ”Š [WebRTC] Waking iOS audio with silent audio in peer.on(open)...
âœ… [WebRTC] iOS audio wake completed in peer.on(open)
âœ…âœ…âœ… [WebRTC] Audio context RESUMED after silent audio trick!
```

## Files Modified
- `/Enclosure/VoiceCallAssets/scriptVoice.js`:
  - Added `playSilentAudioToWakeIOS()` function
  - Replaced direct `audioContext.resume()` with silent audio trick
  - Applied at all 3 strategic points
  - Enhanced logging for wake attempts

## Testing Instructions

1. **Clean build** and run on device
2. **Make call from Android**
3. **Accept from iOS foreground**
4. **Watch for these NEW logs**:

### Look for Wake Attempts:
```
ğŸ”Š [WebRTC] iOS detected - playing silent audio to wake system...
```

### Look for Success:
```
âœ… [WebRTC] Silent audio played - iOS audio system should be active
âœ…âœ…âœ… [WebRTC] Audio context RESUMED after silent audio trick!
```

### Look for Unmute:
```
âœ…âœ…âœ… [WebRTC] Track 0 UNMUTED - microphone is now producing audio!
```

### Check Track State:
```
ğŸ¤ [WebRTC] Track 0: enabled=true, state=live, muted=false  â† Should be false!
```

## Expected Outcome

âœ… **Silent audio plays** â†’ iOS audio system wakes â†’ Audio context resumes â†’ Track unmutes â†’ **Microphone works!**

This is a proven iOS workaround used by many WebRTC apps. The silent audio "unlocks" the audio system without user interaction.

## Fallback If This Doesn't Work

If silent audio also fails/hangs, possible next steps:
1. **Native-to-JS signal**: Call `playSilentAudioToWakeIOS()` from native Swift when CallKit activates
2. **User interaction required**: Show "Tap to activate microphone" button
3. **New getUserMedia**: Request new stream from scratch when muted
4. **Remove audio context entirely**: Don't create AudioContext, let WebRTC handle it

The logs will tell us which approach is needed.
